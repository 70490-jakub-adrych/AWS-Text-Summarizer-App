{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3225be01",
   "metadata": {},
   "source": [
    "# Deploy Pre-trained Summarization Model to SageMaker\n",
    "\n",
    "This notebook deploys the pre-trained BART-CNN model to SageMaker without any training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3426ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install --upgrade pip\n",
    "!pip install boto3 sagemaker\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Initialize SageMaker session\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"SageMaker session bucket: {session.default_bucket()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endpoint name - IMPORTANT: Use the same name expected by your React app\n",
    "endpoint_name = \"summarizer-endpoint\"\n",
    "\n",
    "# Choose instance type - m5.xlarge is a good balance of performance and cost\n",
    "# You can also try ml.t3.medium for free tier compatibility, but it might be slower\n",
    "instance_type = \"ml.m5.xlarge\"  # or \"ml.t3.medium\" for free tier\n",
    "\n",
    "print(f\"Using instance type: {instance_type}\")\n",
    "print(f\"Using endpoint name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5287064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the pre-trained Hugging Face model\n",
    "hub = {\n",
    "    'HF_MODEL_ID': 'facebook/bart-large-cnn',  # model_id from hf.co/models\n",
    "    'HF_TASK': 'summarization'                 # NLP task you want to use\n",
    "}\n",
    "\n",
    "# Create HuggingFaceModel\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub,\n",
    "    role=role,\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    entry_point='inference.py',  # Custom inference script\n",
    "    source_dir='../backend/',    # Path to inference.py file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the endpoint already exists\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "try:\n",
    "    sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"Endpoint {endpoint_name} already exists. Deleting it before deploying new model...\")\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "    # Wait for the endpoint to be deleted\n",
    "    import time\n",
    "    print(\"Waiting for endpoint to be deleted...\")\n",
    "    time.sleep(60)  # Wait for 60 seconds\n",
    "except Exception as e:\n",
    "    if 'Could not find endpoint' in str(e):\n",
    "        print(f\"Endpoint {endpoint_name} does not exist yet. Will create it.\")\n",
    "    else:\n",
    "        print(f\"Error checking endpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2437ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "print(f\"Deploying model to endpoint: {endpoint_name}\")\n",
    "print(\"This may take 5-10 minutes...\")\n",
    "\n",
    "try:\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=instance_type,\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "    print(f\"Model deployed successfully to endpoint: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deploying model: {e}\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Check your AWS account limits in the AWS Console\")\n",
    "    print(\"2. Verify that you have sufficient permissions\")\n",
    "    print(\"3. Check if there are existing endpoints with the same name\")\n",
    "    print(\"4. Try using a different instance type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the endpoint with a sample text\n",
    "import json  # Add this import to fix the NameError\n",
    "\n",
    "sample_text = \"\"\"\n",
    "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price. The deal, first reported by The Real Deal, was for $150 million, according to a source familiar with the deal. Mubadala, an Abu Dhabi investment fund, purchased 90% of the building for $800 million in 2008. Real estate firm Tishman Speyer had owned the other 10%. The buyer is RFR Holding, a New York real estate company. Officials with Tishman and RFR did not immediately respond to a request for comments. It's unclear when the deal will close. The building sold fairly quickly after being publicly placed on the market only two months ago. The sale was handled by CBRE Group. The incentive to sell the building at such a huge loss was due to the soaring rent the owners pay to Cooper Union, a New York college, for the land under the building. The rent is rising from $7.75 million last year to $32.5 million this year to $41 million in 2028. Meantime, rents in the building itself are not rising nearly that fast. While the building is an iconic landmark in the New York skyline, it is competing against newer office towers with large floor plans that are preferred by many tenants. The Chrysler Building was briefly the world's tallest, before it was surpassed by the Empire State Building, which was completed the following year.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Create a SageMaker runtime client for prediction\n",
    "    runtime_client = boto3.client('sagemaker-runtime')\n",
    "    \n",
    "    # Send test data to the endpoint\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps({'text': sample_text})\n",
    "    )\n",
    "    \n",
    "    # Process the response\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    \n",
    "    print(\"Generated summary:\")\n",
    "    print(result['summary'])\n",
    "except Exception as e:\n",
    "    print(f\"Error during inference: {e}\")\n",
    "    print(\"This could be due to an issue with the endpoint setup.\")\n",
    "    print(\"Check the CloudWatch logs for the endpoint for more details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c79eca",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've now deployed a pre-trained summarization model to AWS SageMaker without having to train anything yourself. This endpoint will work with your existing React application as long as:\n",
    "\n",
    "1. The endpoint name matches what's expected in your React app's configuration\n",
    "2. The JSON format for input and output follows the same structure\n",
    "\n",
    "Remember: The model will start incurring charges as long as the endpoint is active. To minimize costs, delete the endpoint when you're not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eae38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to delete the endpoint when you're done\n",
    "# sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "# print(f\"Endpoint {endpoint_name} deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
